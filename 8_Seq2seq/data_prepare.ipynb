{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from fbprophet import Prophet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pd.read_csv('input/raw/datafill.csv',index_col=0)\n",
    "# source_df['2018/1/1 0:00':'2018/4/1 0:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract seasons and years data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_seasons(df,years=[2015,2016,2017,2018],path='input/raw/seasons/'):\n",
    "    for year in years:\n",
    "#         print(year)\n",
    "        if(year == 2018):\n",
    "            df['2018/1/1 0:00':'2018/3/31 23:00'].to_csv(path+f'{year}_spring.csv')\n",
    "        else:\n",
    "            df[f'{year}/1/1 0:00':f'{year}/3/31 23:00'].to_csv(path+f'{year}_spring.csv')\n",
    "            df[f'{year}/4/1 0:00':f'{year}/6/30 23:00'].to_csv(path+f'{year}_summer.csv')\n",
    "            df[f'{year}/7/1 0:00':f'{year}/9/30 23:00'].to_csv(path+f'{year}_autumn.csv')\n",
    "            df[f'{year}/10/1 0:00':f'{year}/12/31 23:00'].to_csv(path+f'{year}_winter.csv')\n",
    "def divide_into_years(df,years=[2015,2016,2017],path='input/raw/years/'):\n",
    "    for year in years:\n",
    "        df[f'{year}/1/1 0:00':f'{year}/12/31 23:00'].to_csv(path+f'{year}_year.csv')\n",
    "            \n",
    "divide_into_seasons(source_df)\n",
    "divide_into_years(source_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate seq2seq datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = {'ds':'TIME','y':'zhexi_in','x1':'xiaoxi_out','x2':'lengshuijiang_add','x3':'xinhua_add','x4':'zhexi_add'}\n",
    "\n",
    "def feature_mapping(df,feature_map):\n",
    "    for key,value in feature_map.items():\n",
    "        df[key] = df[value]\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    return df.drop(feature_map.values(),axis=1)\n",
    "\n",
    "def make_former_Npoints_time_series(df,n):\n",
    "    for i in range(1,n+1):\n",
    "        df[f'current_before_{n-i+1}'] = df['y'].shift(n-i+1)\n",
    "    return df.dropna()\n",
    "# make_former_Npoints_time_series(ts,N)\n",
    "\n",
    "def make_next_Mpoints_time_series(df,m):\n",
    "    for i in range(1,m):\n",
    "        df[f'current_next_{i}'] = df['y'].shift(-i)\n",
    "    return df.dropna()\n",
    "# make_next_Mpoints_time_series(ts,M)\n",
    "# df = feature_mapping(source_df,feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 24\n",
    "M = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_before_24</th>\n",
       "      <th>current_before_23</th>\n",
       "      <th>current_before_22</th>\n",
       "      <th>current_before_21</th>\n",
       "      <th>current_before_20</th>\n",
       "      <th>current_before_19</th>\n",
       "      <th>current_before_18</th>\n",
       "      <th>current_before_17</th>\n",
       "      <th>current_before_16</th>\n",
       "      <th>current_before_15</th>\n",
       "      <th>...</th>\n",
       "      <th>current_before_4</th>\n",
       "      <th>current_before_3</th>\n",
       "      <th>current_before_2</th>\n",
       "      <th>current_before_1</th>\n",
       "      <th>y</th>\n",
       "      <th>current_next_1</th>\n",
       "      <th>current_next_2</th>\n",
       "      <th>current_next_3</th>\n",
       "      <th>current_next_4</th>\n",
       "      <th>current_next_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>180.475</td>\n",
       "      <td>206.634</td>\n",
       "      <td>200.758</td>\n",
       "      <td>183.565</td>\n",
       "      <td>167.91</td>\n",
       "      <td>179.350</td>\n",
       "      <td>162.501</td>\n",
       "      <td>148.392</td>\n",
       "      <td>170.659</td>\n",
       "      <td>152.862</td>\n",
       "      <td>...</td>\n",
       "      <td>152.210</td>\n",
       "      <td>125.898</td>\n",
       "      <td>110.184</td>\n",
       "      <td>127.582</td>\n",
       "      <td>145.932</td>\n",
       "      <td>135.259</td>\n",
       "      <td>113.138</td>\n",
       "      <td>146.560</td>\n",
       "      <td>156.628</td>\n",
       "      <td>140.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>206.634</td>\n",
       "      <td>200.758</td>\n",
       "      <td>183.565</td>\n",
       "      <td>167.910</td>\n",
       "      <td>179.35</td>\n",
       "      <td>162.501</td>\n",
       "      <td>148.392</td>\n",
       "      <td>170.659</td>\n",
       "      <td>152.862</td>\n",
       "      <td>159.296</td>\n",
       "      <td>...</td>\n",
       "      <td>125.898</td>\n",
       "      <td>110.184</td>\n",
       "      <td>127.582</td>\n",
       "      <td>145.932</td>\n",
       "      <td>135.259</td>\n",
       "      <td>113.138</td>\n",
       "      <td>146.560</td>\n",
       "      <td>156.628</td>\n",
       "      <td>140.187</td>\n",
       "      <td>144.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    current_before_24  current_before_23  current_before_22  \\\n",
       "24            180.475            206.634            200.758   \n",
       "25            206.634            200.758            183.565   \n",
       "\n",
       "    current_before_21  current_before_20  current_before_19  \\\n",
       "24            183.565             167.91            179.350   \n",
       "25            167.910             179.35            162.501   \n",
       "\n",
       "    current_before_18  current_before_17  current_before_16  \\\n",
       "24            162.501            148.392            170.659   \n",
       "25            148.392            170.659            152.862   \n",
       "\n",
       "    current_before_15  ...  current_before_4  current_before_3  \\\n",
       "24            152.862  ...           152.210           125.898   \n",
       "25            159.296  ...           125.898           110.184   \n",
       "\n",
       "    current_before_2  current_before_1        y  current_next_1  \\\n",
       "24           110.184           127.582  145.932         135.259   \n",
       "25           127.582           145.932  135.259         113.138   \n",
       "\n",
       "    current_next_2  current_next_3  current_next_4  current_next_5  \n",
       "24         113.138         146.560         156.628         140.187  \n",
       "25         146.560         156.628         140.187         144.081  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/raw/seasons/2015_spring.csv')\n",
    "df = feature_mapping(df,feature_map)\n",
    "df = pd.DataFrame(df['y'])\n",
    "df = make_next_Mpoints_time_series(df,M)\n",
    "df = make_former_Npoints_time_series(df,N)\n",
    "df = pd.concat((df[df.columns[M:]],df[df.columns[:M]]),axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/raw/years/2015_year.csv',\n",
       " 'input/raw/years/2016_year.csv',\n",
       " 'input/raw/years/2017_year.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "def generate_seq2seq_data(df,n,m,save_path=None):\n",
    "    df = feature_mapping(df,feature_map)\n",
    "    df = pd.DataFrame(df['y'])\n",
    "    df = make_next_Mpoints_time_series(df,m)\n",
    "    df = make_former_Npoints_time_series(df,n)\n",
    "    df = pd.concat((df[df.columns[m:]],df[df.columns[:m]]),axis=1)\n",
    "    if(save_path != None):\n",
    "        df.to_csv(save_path)\n",
    "    return df\n",
    "def get_raw_csv(path):\n",
    "    return glob.glob(path+'*.csv')\n",
    "# get_raw_csv('input/raw/seasons/')\n",
    "get_raw_csv('input/raw/years/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015_year.csv\n",
      "(8731, 30) \n",
      "\n",
      "2016_year.csv\n",
      "(8751, 30) \n",
      "\n",
      "2017_year.csv\n",
      "(8732, 30) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_csv_files = get_raw_csv('input/raw/years/')\n",
    "for raw_csv_file in raw_csv_files:\n",
    "    df = pd.read_csv(raw_csv_file)\n",
    "#     print(df.columns)\n",
    "    name = raw_csv_file.split('/')[-1]\n",
    "#     print(name)\n",
    "    df = generate_seq2seq_data(df,N,M,'input/prepared/years/'+name)\n",
    "    print(name)\n",
    "    print(df.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015_winter.csv\n",
      "(2179, 30) \n",
      "\n",
      "2015_spring.csv\n",
      "(2131, 30) \n",
      "\n",
      "2016_autumn.csv\n",
      "(2176, 30) \n",
      "\n",
      "2015_summer.csv\n",
      "(2155, 30) \n",
      "\n",
      "2017_winter.csv\n",
      "(2181, 30) \n",
      "\n",
      "2016_spring.csv\n",
      "(2155, 30) \n",
      "\n",
      "2016_summer.csv\n",
      "(2154, 30) \n",
      "\n",
      "2017_summer.csv\n",
      "(2154, 30) \n",
      "\n",
      "2017_spring.csv\n",
      "(2131, 30) \n",
      "\n",
      "2016_winter.csv\n",
      "(2179, 30) \n",
      "\n",
      "2018_spring.csv\n",
      "(2131, 30) \n",
      "\n",
      "2015_autumn.csv\n",
      "(2179, 30) \n",
      "\n",
      "2017_autumn.csv\n",
      "(2179, 30) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_csv_files = get_raw_csv('input/raw/seasons/')\n",
    "for raw_csv_file in raw_csv_files:\n",
    "    df = pd.read_csv(raw_csv_file)\n",
    "#     print(df.columns)\n",
    "    name = raw_csv_file.split('/')[-1]\n",
    "#     print(name)\n",
    "    df = generate_seq2seq_data(df,N,M,'input/prepared/seasons/'+name)\n",
    "    print(name)\n",
    "    print(df.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
